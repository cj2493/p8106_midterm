---
title: "P8106_midterm"
author: "Courtney Johnson & Jaisal Amin"
date: "March 25, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(mgcv)
library(patchwork)
```

## Data

clean and also only keep variables that are a numerical value (only covered numerical modeling so far)
```{r, import}
master = read_csv("./master.csv") %>%
  janitor::clean_names() %>%
  mutate(sex = factor(sex, levels = c("male", "female")),
         age = factor(age, levels = c("5-14 years", "15-24 years", "25-34 years", 
                                      "35-54 years", "55-74 years", "75+ years"))) %>%
  rename(prominent_gen = generation) %>%
  select(suicides_100k_pop, everything())

master_num = master %>%
  select(suicides_100k_pop, year, sex, age, population, gdp_for_year, gdp_per_capita)  %>%
  mutate(sex = as.numeric(sex),
         age = as.numeric(age))
```
Here we have changed the age variable to a numerical to enable easier numerical analysis, but remember that the categories are: 1: 5-14, 2: 15-24, 3: 25-34 , 4: 35-54, 5: 55-74, 6: 75+

Also we did not include hdi because there were NAs
## Create x and y matrices for modeling
```{r, model_matrices}
ctrl1 = trainControl(method = "cv", number = 10)

set.seed(1)

sample = sample.int(n = nrow(master_num), size = floor(0.75*nrow(master_num)), replace = F)

x = model.matrix(suicides_100k_pop ~., master_num)[,-1]
y = master_num$suicides_100k_pop

train = master_num[sample,]
test = master_num[-sample,]

x_train = model.matrix(suicides_100k_pop~., train)[,-1]
y_train = train$suicides_100k_pop

x_test = model.matrix(suicides_100k_pop~., test)[,-1]
y_test = test$suicides_100k_pop
```

## Exploratory analysis and visualization
```{r, eda}
featurePlot(x, y, plot = "scatter", labels = c("","Y"),
            type = c("p"), layout = c(3, 2), alpha = 0.5)
hist(master_num$suicides_100k_pop)
qqnorm(master_num$suicides_100k_pop)
qqline(master_num$suicides_100k_pop)
cor(master_num)
pairs(master_num)
```

## Fit a linear model
```{r, lm}
set.seed(1)

lm.fit = train(x_train, y_train,
               method = "lm",
               trControl = ctrl1)

predy.lm = predict(lm.fit$finalModel, newdata = data.frame(x_test))
mean((predy.lm - y_test)^2)
```
test MSE = 285.0895

## Fit Ridge Regression
```{r, ridge}
set.seed(1)

ridge.fit = train(x_train, y_train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 0,
                                         lambda = exp(seq(-1, 10, length = 100))),
                  trControl = ctrl1)

predy.ridge = predict(ridge.fit$finalModel, newx = x_test, s = ridge.fit$bestTune$lambda, type = "response")
mean((predy.ridge - y_test)^2)
```
test error is 285.352

## Fit Lasso Regression
```{r, lasso}
set.seed(1)
lasso.fit = train(x_train, y_train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1,
                                         lambda = exp(seq(-1, 5, length = 100))),
                  trControl = ctrl1)

predy.lasso = predict(lasso.fit$finalModel, newx = x_test, s = lasso.fit$bestTune$lambda, type = "response")

coef.lasso = predict(lasso.fit$finalModel, newx = x_test, s = lasso.fit$bestTune$lambda, type = "coefficients")

coef.lasso

mean((predy.lasso - y_test)^2)
```
test error 285.7102, 4 nonzero coefficients and one intercept

## Fit PCR
```{r, pcr}
set.seed(1)
pcr.fit = train(x, y,
                  method = "pcr",
                  tuneLength = 5,
                  trControl = ctrl1,
                  scale = TRUE)

predy.pcr = predict(pcr.fit$finalModel, newdata = x_test, ncomp = pcr.fit$bestTune$ncomp)

mean((predy.pcr - y_test)^2)
```
285.2069


## Fit polynomial regression
```{r, poly}
set.seed(1)
gdp1 = lm(suicides_100k_pop ~ gdp_per_capita, data = master_num)

gdp2 = lm(suicides_100k_pop ~ poly(gdp_per_capita, 2), data = master_num)

gdp3 = lm(suicides_100k_pop ~ poly(gdp_per_capita, 3), data = master_num)

gdp4 = lm(suicides_100k_pop ~ poly(gdp_per_capita, 4), data = master_num)

anova(gdp1, gdp2, gdp3, gdp4)

plot1 = ggplot(data = master_num, aes(x = gdp_per_capita, y = suicides_100k_pop)) + 
  geom_point(color = 'blue') +
  geom_line(color = 'red', aes(x = gdp_per_capita, y = predict(gdp1, master_num))) +
  labs(title = "Polynomial, Degree = 1")

plot2 = ggplot(data = master_num, aes(x = gdp_per_capita, y = suicides_100k_pop)) + 
  geom_point(color = 'blue') +
  geom_line(color = 'red', aes(x = gdp_per_capita, y = predict(gdp2, master_num))) +
  labs(title = "Polynomial, Degree = 2")

plot3 = ggplot(data = master_num, aes(x = gdp_per_capita, y = suicides_100k_pop)) + 
  geom_point(color = 'blue') +
  geom_line(color = 'red', aes(x = gdp_per_capita, y = predict(gdp3, master_num))) +
  labs(title = "Polynomial, Degree = 3")

plot4 = ggplot(data = master_num, aes(x = gdp_per_capita, y = suicides_100k_pop)) + 
  geom_point(color = 'blue') +
  geom_line(color = 'red', aes(x = gdp_per_capita, y = predict(gdp4, master_num))) +
  labs(title = "Polynomial, Degree = 4")

plot1 + plot2 + plot3 + plot4

gdp1_cv = train(suicides_100k_pop ~ gdp_per_capita,
                data = train,
                method = "lm",
                trControl = ctrl1)

gdp2_cv = train(suicides_100k_pop ~ poly(gdp_per_capita, 2),
                data = train,
                method = "lm",
                trControl = ctrl1)

gdp3_cv = train(suicides_100k_pop ~ poly(gdp_per_capita, 3),
                data = train,
                method = "lm",
                trControl = ctrl1)

gdp4_cv = train(suicides_100k_pop ~ poly(gdp_per_capita, 4),
                data = train,
                method = "lm",
                trControl = ctrl1)

resamp = resamples(list(lm1 = gdp1_cv, lm2 = gdp2_cv, lm3 = gdp3_cv, lm4 = gdp4_cv))

summary(resamp)

predy.gdp2 = predict(gdp2, newdata = data.frame(x_test))
mean((predy.gdp2 - y_test)^2)

predy.gdp3 = predict(gdp3, newdata = data.frame(x_test))
mean((predy.gdp3 - y_test)^2)

predy.gdp4 = predict(gdp4, newdata = data.frame(x_test))
mean((predy.gdp4 - y_test)^2)
```
gdp2 MSE 390.6915
gdp3 MSE 390.5242
gdp4 MSe 390.5099

## Fit GAM
```{r, gam}
set.seed(1)
gam.m1 = gam(suicides_100k_pop ~ year + sex + age + population + gdp_for_year + gdp_per_capita, data = master_num)
gam.m2 = gam(suicides_100k_pop ~ year + sex + age + population + s(gdp_for_year) + gdp_per_capita, data = master_num)

anova(gam.m1, gam.m2, test = "F")
plot(gam.m2)

gam.fit = train(x_train, y_train,
                method = "gam",
                tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE, FALSE)),
                trControl = ctrl1)
gam.fit$bestTune
gam.fit$finalModel

predy.gam = predict(gam.fit, newdata = data.frame(x_test))
mean((predy.gam - y_test)^2)
```
278.8389

## Boxplot
```{r, boxplot}
resamp = resamples(list(linear = lm.fit,
                        ridge = ridge.fit,
                        lasso = lasso.fit,
                        pcr = pcr.fit,
                        gam = gam.fit,
                        poly4 = gdp4_cv))

bwplot(resamp, metric = "RMSE")
```